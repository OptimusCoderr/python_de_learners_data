# -*- coding: utf-8 -*-
"""exploring_gpt4all

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MQSpApD-yzV7kMo_Wv84bmjdI04pU3f3
"""

!pip install langchain sentence-transformers transformers huggingface huggingface_hub llama-cpp-python

from huggingface_hub import hf_hub_download

#Download the model
hf_hub_download(repo_id="LLukas22/gpt4all-lora-quantized-ggjt", 
                filename="ggjt-model.bin", 
                local_dir=".")

from langchain.llms import LlamaCpp
from langchain import PromptTemplate, LLMChain

template = """Question: {question}

Answer: Let's think step by step."""

prompt = PromptTemplate(template=template, input_variables=["question"])

llm = LlamaCpp(model_path="/content/ggjt-model.bin")

question = "What NFL team won the Super Bowl in the year Justin Bieber was born?"

llm(question)

llm_chain = LLMChain(prompt=prompt, llm=llm)

llm_chain.run(question)

#Two areas to check.
from langchain.chains import LLMRequestsChain
from langchain.agents import create_pandas_dataframe_agent

import pandas as pd

df = pd.read_csv('/content/space_shortened.csv')

gpt4llagent = create_pandas_dataframe_agent(llm,
                                      df, 
                                      verbose=True)

gpt4llagent.run("How many travellers are in the dataset?")

req_template = """Between >>> and <<< are the raw search result text from google.
Extract the answer to the question '{query}' or say "not found" if the information is not contained.
Use the format
Extracted:<answer or "not found">
>>> {requests_result} <<<
Extracted:"""

req_prompt = PromptTemplate(
    input_variables=["query", "requests_result"],
    template=req_template,
)

netchain = LLMRequestsChain(llm_chain = LLMChain(llm=llm, 
                                              prompt=req_prompt))

question = "What are the Three biggest states in India and its population?"

inputs = {
    "query": question,
    "url": "https://www.google.com/search?q=" + question.replace(" ", "+")
}

netchain(inputs)

from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.agents import AgentType

import os
os.environ['SERPER_API_KEY']='afe3bf4e0ffaba00be5a8bb06eecea7d30d45e4404872d76117f0d96da083e86'

tools = load_tools(["google-serper"], llm=llm)

agent = initialize_agent(tools, 
                         llm, 
                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, 
                         verbose=True)

agent.run("What is the weather in Delhi?")





from langchain.embeddings import LlamaCppEmbeddings

llama = LlamaCppEmbeddings(model_path="/content/ggjt-model.bin")

text = "This is a test document."

llama.embed_query(text)

