{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jqqmjvfGXO7n"
      },
      "outputs": [],
      "source": [
        "pip install txtinstruct > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "txtinstruct consists of three components to help train instruction-following models. \n",
        "\n",
        "## 3-components\n",
        " \n",
        "**Statement generation** models create a statement from a context. This statement can be a question or request to describe a concept depending on the model.\n",
        "\n",
        "**Knowledge source** for pulling context. An example knowledge source used in this notebook is a txtai embeddings index of the full Wikipedia dataset.\n",
        "\n",
        "**Large language model (LLM)** for translating source statements into target statements. A prompt is used in combination with the knowledge source context to generate the target text"
      ],
      "metadata": {
        "id": "-Oed3R_GXbuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "from txtinstruct.models import StatementGenerator\n",
        "\n",
        "# Load SQuAD dataset\n",
        "dataset = load_dataset(\"squad\", split=\"train\")\n",
        "\n",
        "# Train model\n",
        "generator = StatementGenerator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cGrnIcOXTR9",
        "outputId": "db9f15c6-3999-4e5a-fd18-4c55003d6f11"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = generator(\n",
        "    \"google/flan-t5-small\",\n",
        "    dataset,\n",
        "    \"sequence-sequence\",\n",
        "    learning_rate=1e-3,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=128 // 16,\n",
        "    num_train_epochs=0.001,\n",
        "    logging_steps=100,\n",
        ")\n",
        "#Note that we only trained the model for a fraction of an epoch \n",
        "#for expediency. Under normal circumstances, num_train_epochs \n",
        "#would be at least 3."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "bJENeVh_XTWr",
        "outputId": "24029d49-b447-49eb-9353-9ca4d699aa04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset generator (/root/.cache/huggingface/datasets/generator/default-73577150cf9f0b45/0.0.0)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-73577150cf9f0b45/0.0.0/cache-3682b50c6766f69b.arrow\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from txtai.pipeline import Sequences\n",
        "\n",
        "# Load statement generation model\n",
        "statements = Sequences((model, tokenizer))\n",
        "\n",
        "# Run example prompt\n",
        "statements(\"\"\"Generate a question using the context below.\n",
        "### Context:\n",
        "Hugging face is an open-source platform for hosting \n",
        "all kind of AI language models.\"\"\")\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S0zsinGPXTab",
        "outputId": "17bfea85-b8e5-4b21-bcc5-7776ef623a12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is an open-source platform for hosting all kinds of AI language models?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from txtai.embeddings import Embeddings\n",
        "from txtinstruct.data import DatasetBuilder\n",
        "\n",
        "# Load embeddings\n",
        "embeddings = Embeddings()\n",
        "embeddings.load(provider=\"huggingface-hub\", \n",
        "                container=\"neuml/txtai-wikipedia\")"
      ],
      "metadata": {
        "id": "NqMiDBaLXTe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query templates\n",
        "templates = [\n",
        "    \"Tell me about {text}\",\n",
        "    \"Give an explanation on {text}\",\n",
        "    \"Provide a quick summary on {text}\",\n",
        "    \"Explain {text} in simple terms\",\n",
        "    \"Describe {text}\"\n",
        "]"
      ],
      "metadata": {
        "id": "To_cqzdHXTk-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build dataset\n",
        "builder = DatasetBuilder(Sequences(\"google/flan-t5-base\"), \n",
        "                         statements, \n",
        "                         templates)\n",
        "builder(\n",
        "    embeddings.search(\"SELECT id, text FROM txtai WHERE similar('machine learning') AND percentile >= 0.99 LIMIT 5\"),\n",
        "    5,\n",
        "    \"data.json\"\n",
        ")"
      ],
      "metadata": {
        "id": "ZFpxL2IAiZlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from txtinstruct.models import Instructor\n",
        "\n",
        "# Read in generated dataset\n",
        "with open(\"data.json\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)"
      ],
      "metadata": {
        "id": "gbidKCKXoKni"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UquHw0_oMj9",
        "outputId": "8d313933-75a4-4dd7-ac83-9da6e3fcabaa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': \"Machine learning (ML) is a field of inquiry devoted to understanding and building methods that 'learn', that is, methods that leverage data to improve performance on some set of tasks. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, agriculture, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks. \\nA subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers, but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.  In its application across business problems, machine learning is also referred to as predictive analytics.\",\n",
              " 'statements': [{'source': 'Machine learning is a field of inquiry devoted to understanding and building methods that leverage data to improve performance on some set of tasks?',\n",
              "   'target': \"I don't have data on that\"},\n",
              "  {'source': 'Tell me about Machine learning',\n",
              "   'target': \"Machine learning (ML) is a field of inquiry devoted to understanding and building methods that 'learn'\"},\n",
              "  {'source': 'What is the study of machine learning attacks on machine learning algorithms?',\n",
              "   'target': \"I don't have data on that\"}]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instruction-tune model\n",
        "instructor = Instructor()\n",
        "model, tokenizer = instructor(\n",
        "    \"google/flan-t5-small\", \n",
        "    data,\n",
        "    \"sequence-sequence\",\n",
        "    learning_rate=1e-3,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=128 // 8,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=100,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "AAhTmD30lkfO",
        "outputId": "2e0c6870-b701-4002-d4e3-2d3b159b8aff"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset generator (/root/.cache/huggingface/datasets/generator/default-919ea8c1c4b83f0a/0.0.0)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/generator/default-919ea8c1c4b83f0a/0.0.0/cache-8b2ac68ef7f1afc6.arrow\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:37, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from txtai.pipeline import Extractor\n",
        "\n",
        "def prompt(text):\n",
        "    template = \"Answer the following question using only the context below. Give a detailed answer. \"\n",
        "    template += \"Say 'I don't have data on that' when the question can't be answered.\\n\"\n",
        "    template += f\"Question: {text}\\n\"\n",
        "    template += \"Context: \"\n",
        "\n",
        "    return template\n"
      ],
      "metadata": {
        "id": "l5zxnU2ZoVNw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This model is from hugging face\n",
        "extractor = Extractor(\n",
        "    embeddings,\n",
        "    Sequences(\"google/flan-t5-small\")\n",
        ")\n",
        "\n",
        "extractor([{\n",
        "    \"query\": \"Tell me about Linux\",\n",
        "    \"question\": prompt(\"Tell me about Linux\")\n",
        "}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGgIBbgfoVGU",
        "outputId": "0a1361e7-af0f-41b6-945e-02fa74a56558"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer': 'Linux'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This model is trained in this colab notebook\n",
        "extractor = Extractor(\n",
        "    embeddings,\n",
        "    Sequences((model, tokenizer))\n",
        ")\n",
        "\n",
        "extractor([{\n",
        "    \"query\": \"Tell me about Linux\",\n",
        "    \"question\": prompt(\"Tell me about Linux\")\n",
        "}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-kUs5zXoVAz",
        "outputId": "84a5ccea-91d0-416f-8557-472c5b58afbf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer': 'Linux (or ) is a family of open-source Unix-like operating systems based on the Linux kernel, an operating system kernel first released on September 17, 1991, by Linus Torvalds. Linux is typically packaged as a Linux distribution, which includes the kernel and supporting system software and libraries, many of which are provided by the GNU Project.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extractor([{\n",
        "    \"query\": \"Tell me about adversarial Machine Learning\",\n",
        "    \"question\": prompt(\"Tell me about adversarial Machine Learning\")\n",
        "}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAi0fAPdopVm",
        "outputId": "f9031319-cbe7-4150-d471-ed49b42a7ff8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answer': 'Adversarial machine learning is the study of the attacks on machine learning algorithms, and of the defenses against such attacks'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XRl-4mjaqTAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOaAQNjxqS8s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}