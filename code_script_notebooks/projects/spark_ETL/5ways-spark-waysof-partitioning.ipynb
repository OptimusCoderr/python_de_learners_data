{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-03T02:38:46.011719Z","iopub.execute_input":"2023-04-03T02:38:46.012174Z","iopub.status.idle":"2023-04-03T02:39:35.160664Z","shell.execute_reply.started":"2023-04-03T02:38:46.012133Z","shell.execute_reply":"2023-04-03T02:39:35.158812Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting py4j==0.10.9.5\n  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=25f8d41ad533ad0c95a7b75061c64a73bda6bac44b49151ab733d2d52f16f802\n  Stored in directory: /root/.cache/pip/wheels/5a/54/9b/a89cac960efb57c4c35d41cc7c9f7b80daa21108bc376339b7\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\n  Attempting uninstall: py4j\n    Found existing installation: py4j 0.10.9.7\n    Uninstalling py4j-0.10.9.7:\n      Successfully uninstalled py4j-0.10.9.7\nSuccessfully installed py4j-0.10.9.5 pyspark-3.3.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Ways of Clusters : Spark\n\nWith any data, we want to always cluster, categorize, partition and divide to learn fast. How best Spark supports it? \n\nNotebook discusses the way we can cluster the data inside the spark table. \n\n1) Distribute By\n\n2) Cluster By\n\n3) Partition By\n\n4) Bucketing By\n\n5) Group By\n\nWe will see each of these using the Dmart Sales Data","metadata":{}},{"cell_type":"code","source":"#Creating the Spark Session\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\n\nspark = SparkSession. \\\n    builder. \\\n    appName('Cluster_Spark'). \\\n    getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:19:38.703595Z","iopub.execute_input":"2023-04-03T03:19:38.704350Z","iopub.status.idle":"2023-04-03T03:19:44.242238Z","shell.execute_reply.started":"2023-04-03T03:19:38.704300Z","shell.execute_reply":"2023-04-03T03:19:44.240719Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","output_type":"stream"},{"name":"stdout","text":"23/04/03 03:19:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"#importing the dataset\n\nsales_raw = spark.read.csv('/kaggle/input/datasetbackups/dmart/Sales.csv',\n                          inferSchema=True, sep='\\t',header=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:20:42.420741Z","iopub.execute_input":"2023-04-03T03:20:42.421191Z","iopub.status.idle":"2023-04-03T03:20:50.744181Z","shell.execute_reply.started":"2023-04-03T03:20:42.421147Z","shell.execute_reply":"2023-04-03T03:20:50.742902Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"#Creating database so the Spark SQL tables can be created. \nspark.sql(\"CREATE DATABASE dmart_db\")\nspark.sql(\"USE dmart_db\")","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:21:11.823812Z","iopub.execute_input":"2023-04-03T03:21:11.824241Z","iopub.status.idle":"2023-04-03T03:21:11.977149Z","shell.execute_reply.started":"2023-04-03T03:21:11.824204Z","shell.execute_reply":"2023-04-03T03:21:11.975737Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DataFrame[]"},"metadata":{}}]},{"cell_type":"code","source":"sales_raw.createOrReplaceTempView(\"sales_view\")","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:23:13.494345Z","iopub.execute_input":"2023-04-03T03:23:13.494748Z","iopub.status.idle":"2023-04-03T03:23:13.538750Z","shell.execute_reply.started":"2023-04-03T03:23:13.494713Z","shell.execute_reply":"2023-04-03T03:23:13.537729Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Views are temporary tables\nspark.sql(\"SHOW TABLES\").show()","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:23:27.964812Z","iopub.execute_input":"2023-04-03T03:23:27.965864Z","iopub.status.idle":"2023-04-03T03:23:28.321046Z","shell.execute_reply.started":"2023-04-03T03:23:27.965823Z","shell.execute_reply":"2023-04-03T03:23:28.319684Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"+---------+----------+-----------+\n|namespace| tableName|isTemporary|\n+---------+----------+-----------+\n|         |sales_view|       true|\n+---------+----------+-----------+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Introducing Distributed By\n\nThe DISTRIBUTE BY clause is used to repartition the data based on the input expressions. Unlike the CLUSTER BY clause, this does not sort the data within each partition.","metadata":{}},{"cell_type":"code","source":"SQL = spark.sql\n\nSQL(\"\"\"SELECT ID, Date, GMV, MRP, Units_sold FROM sales_view LIMIT 5\"\"\").show(2)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:25:24.264840Z","iopub.execute_input":"2023-04-03T03:25:24.265257Z","iopub.status.idle":"2023-04-03T03:25:24.635322Z","shell.execute_reply.started":"2023-04-03T03:25:24.265223Z","shell.execute_reply":"2023-04-03T03:25:24.634069Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"+----------------+----------------+----+----+----------+\n|              ID|            Date| GMV| MRP|Units_sold|\n+----------------+----------------+----+----+----------+\n|ACCCX3S58G7B5F6P|17-10-2015 15:11|6400|7190|         1|\n|ACCCX3S58G7B5F6P|19-10-2015 10:07|6900|7190|         1|\n+----------------+----------------+----+----+----------+\nonly showing top 2 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"SQL(\"\"\"SELECT ID, Date, GMV, MRP, Units_sold \n        FROM sales_view\n        DISTRIBUTE BY CAST(GMV as int)\n        LIMIT 20\"\"\").show()","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:28:59.159807Z","iopub.execute_input":"2023-04-03T03:28:59.160185Z","iopub.status.idle":"2023-04-03T03:29:01.364272Z","shell.execute_reply.started":"2023-04-03T03:28:59.160155Z","shell.execute_reply":"2023-04-03T03:29:01.362861Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"[Stage 21:==============>                                           (1 + 3) / 4]\r","output_type":"stream"},{"name":"stdout","text":"+----------------+----------------+----+-----+----------+\n|              ID|            Date| GMV|  MRP|Units_sold|\n+----------------+----------------+----+-----+----------+\n|ACCCYH98AZH5WHDF|04-10-2015 10:53|9900|15200|         1|\n|ACCCYZFZZJYF95F3|04-10-2015 15:22|8389|10400|         1|\n|ACCCYZFZZJYF95F3|03-10-2015 22:31|8389|10400|         1|\n|ACCCYZFZZJYF95F3|02-10-2015 10:03|8389|10400|         1|\n|ACCCYZFZZJYF95F3|02-10-2015 15:28|8389|10400|         1|\n|ACCCYZFZZJYF95F3|02-10-2015 17:08|8389|10400|         1|\n|ACCCYZFZZJYF95F3|03-10-2015 18:02|8389|10400|         1|\n|ACCCYZFZZJYF95F3|05-10-2015 10:54|8389|10400|         1|\n|ACCCYZFZZJYF95F3|04-10-2015 20:43|8389|10400|         1|\n|ACCCZ34CBVZJTVQF|30-10-2015 15:52|3175| 3999|         1|\n|ACCCZ34CBVZJTVQF|27-10-2015 13:36|3175| 3999|         1|\n|ACCCZ34CBZFWKPBQ|20-10-2015 17:27|1829| 3500|         1|\n|ACCCZ34CBZFWKPBQ|18-10-2015 19:32|1829| 3500|         1|\n|ACCCZ34CBZFWKPBQ|20-10-2015 09:37|1829| 3500|         1|\n|ACCCZ34CBZFWKPBQ|16-10-2015 04:53|1829| 3500|         1|\n|ACCCZ34CBZFWKPBQ|17-10-2015 15:22|1829| 3500|         1|\n|ACCCZ34CBZFWKPBQ|21-10-2015 21:36|1829| 3500|         1|\n|ACCCZ34CBZFWKPBQ|22-10-2015 13:24|1829| 3500|         1|\n|ACCCZ34CBZFWKPBQ|18-10-2015 19:32|1829| 3500|         1|\n|ACCCZ34CBZFWKPBQ|16-10-2015 18:54|1829| 3500|         1|\n+----------------+----------------+----+-----+----------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"## Introducing Cluster by\n\nThe CLUSTER BY clause is used to first repartition the data based on the input expressions and then sort the data within each partition. This is semantically equivalent to performing a **DISTRIBUTE BY** followed by a **SORT BY**.","metadata":{}},{"cell_type":"code","source":"SQL(\"SET spark.sql.shuffle.partitions = 2;\")","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:33:28.629225Z","iopub.execute_input":"2023-04-03T03:33:28.630304Z","iopub.status.idle":"2023-04-03T03:33:28.660530Z","shell.execute_reply.started":"2023-04-03T03:33:28.630260Z","shell.execute_reply":"2023-04-03T03:33:28.658870Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"DataFrame[key: string, value: string]"},"metadata":{}}]},{"cell_type":"code","source":"SQL(\"\"\"SELECT ID, Date, GMV, MRP, Units_sold \n        FROM sales_view\n        CLUSTER BY MRP\n        LIMIT 20\"\"\").show()","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:33:49.669821Z","iopub.execute_input":"2023-04-03T03:33:49.670304Z","iopub.status.idle":"2023-04-03T03:33:51.706157Z","shell.execute_reply.started":"2023-04-03T03:33:49.670262Z","shell.execute_reply":"2023-04-03T03:33:51.704881Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"[Stage 39:=============================>                            (2 + 2) / 4]\r","output_type":"stream"},{"name":"stdout","text":"+----------------+----------------+---+---+----------+\n|              ID|            Date|GMV|MRP|Units_sold|\n+----------------+----------------+---+---+----------+\n|CGEECC2GSWH4YYYY|29-11-2015 15:46| 79| 49|         1|\n|CGEECC2GGDHVCH7F|22-12-2015 18:24| 79| 49|         1|\n|CGEECC2GSWH4YYYY|07-12-2015 22:23| 79| 49|         1|\n|CGEECC2GSWH4YYYY|24-12-2015 15:25| 79| 49|         1|\n|CGEECC2GSWH4YYYY|05-12-2015 15:25| 79| 49|         1|\n|CGEECC2GSWH4YYYY|11-12-2015 12:00| 79| 49|         1|\n|CGEECC2GSWH4YYYY|03-12-2015 09:29| 79| 49|         1|\n|CGEECC2GSWH4YYYY|23-12-2015 10:22| 79| 49|         1|\n|CGEECC2GGDHVCH7F|07-01-2016 18:39| 79| 49|         1|\n|CGEECC2GGDHVCH7F|18-01-2016 19:47| 60| 49|         1|\n|CGEECC2GGDHVCH7F|24-01-2016 16:26| 60| 49|         1|\n|CGEECC2GGDHVCH7F|11-01-2016 21:04| 79| 49|         1|\n|CGEECC2GGDHVCH7F|03-01-2016 00:58| 79| 49|         1|\n|CGEECC2GGDHVCH7F|20-01-2016 17:09| 60| 49|         1|\n|CGEECC2GSWH4YYYY|22-01-2016 21:08| 49| 49|         1|\n|CGEECC2GSWH4YYYY|15-01-2016 06:57| 49| 49|         1|\n|CGEECC2GSWH4YYYY|18-01-2016 19:53| 49| 49|         1|\n|CGEECC2GSWH4YYYY|22-01-2016 16:49| 39| 49|         1|\n|CGEECC2GSWH4YYYY|24-01-2016 20:51| 49| 49|         1|\n|CGEECC2GSWH4YYYY|20-01-2016 17:10| 49| 49|         1|\n+----------------+----------------+---+---+----------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"## Group By Needs no Intro\n\nThe purpose of groupby is for aggregating the values inside the categories. While the ideas we are discussing here is about clustering the data for better understanding / viewing","metadata":{}},{"cell_type":"code","source":"SQL(\"\"\"SELECT GMV, ROUND(AVG(MRP), 1) as average_mrp, \n            SUM(Units_sold) as total_units,\n            SUM(MRP * Units_sold) as total_sales\n        FROM sales_view\n        GROUP BY GMV\n        LIMIT 20\"\"\").show()","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:38:10.602993Z","iopub.execute_input":"2023-04-03T03:38:10.603433Z","iopub.status.idle":"2023-04-03T03:38:12.256141Z","shell.execute_reply.started":"2023-04-03T03:38:10.603401Z","shell.execute_reply":"2023-04-03T03:38:12.254864Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"[Stage 51:==============>                                           (1 + 3) / 4]\r","output_type":"stream"},{"name":"stdout","text":"+----+-----------+-----------+-----------+\n| GMV|average_mrp|total_units|total_sales|\n+----+-----------+-----------+-----------+\n|6900|     7763.9|         49|     380429|\n|1990|     3884.1|       1408|    5375955|\n|1618|     2798.8|         15|      40084|\n|3324|     3508.0|          8|      22037|\n|6749|    13957.8|        254|    3545274|\n|6003|     6718.0|          6|      38580|\n|6073|     7574.5|          2|      15149|\n|6002|     7150.0|          1|       7150|\n|6565|     7584.8|         52|     394410|\n|6554|     7150.0|         12|      85800|\n|6533|     7174.3|         14|     100440|\n|6133|     7150.0|          1|       7150|\n|6695|     7198.6|          7|      50390|\n|6589|     7208.4|         13|      93709|\n|6550|     8355.4|         63|     526390|\n|6435|     7454.0|         20|     149079|\n|6500|    10908.2|         56|     575472|\n|5898|     7256.0|          6|      44280|\n|6700|     9848.1|         14|     137873|\n|6025|     7377.4|          9|      66397|\n+----+-----------+-----------+-----------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"# Moving to Partitioning\n\nPartitioning is executed when the table is written as files to the hadoop/ local file system. The above commands create concept level partitioning. While partitioning makes the partitioning physically at files and folder level.  ","metadata":{}},{"cell_type":"code","source":"sales_raw.printSchema()","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:46:19.669466Z","iopub.execute_input":"2023-04-03T03:46:19.670028Z","iopub.status.idle":"2023-04-03T03:46:19.679357Z","shell.execute_reply.started":"2023-04-03T03:46:19.669985Z","shell.execute_reply":"2023-04-03T03:46:19.677596Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"root\n |-- ID: string (nullable = true)\n |-- Date: string (nullable = true)\n |-- ID_Order: double (nullable = true)\n |-- ID_Item_ordered: double (nullable = true)\n |-- GMV: string (nullable = true)\n |-- Units_sold: integer (nullable = true)\n |-- SLA: integer (nullable = true)\n |-- Product_Category: string (nullable = true)\n |-- Analytic_Category: string (nullable = true)\n |-- Sub_category: string (nullable = true)\n |-- product_analytic_vertical: string (nullable = true)\n |-- MRP: integer (nullable = true)\n |-- Procurement_SLA: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Lets create a table that has partition builtin\n\nsales_raw.write.saveAsTable(\"sales_partition\",\n                           mode='overwrite',\n                           partitionBy='GMV',\n                           format='parquet')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:50:09.279685Z","iopub.execute_input":"2023-04-03T03:50:09.280123Z","iopub.status.idle":"2023-04-03T03:53:48.150436Z","shell.execute_reply.started":"2023-04-03T03:50:09.280087Z","shell.execute_reply":"2023-04-03T03:53:48.149429Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"SQL(\"\"\"SHOW PARTITIONS sales_partition\"\"\").show(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:58:50.567888Z","iopub.execute_input":"2023-04-03T03:58:50.569658Z","iopub.status.idle":"2023-04-03T03:58:50.843432Z","shell.execute_reply.started":"2023-04-03T03:58:50.569597Z","shell.execute_reply":"2023-04-03T03:58:50.842205Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"+---------+\n|partition|\n+---------+\n|    GMV= |\n|    GMV=0|\n|   GMV=10|\n|  GMV=100|\n| GMV=1000|\n+---------+\nonly showing top 5 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"SQL(\"\"\"DESCRIBE TABLE EXTENDED sales_partition\"\"\").show()","metadata":{"execution":{"iopub.status.busy":"2023-04-03T03:59:09.383366Z","iopub.execute_input":"2023-04-03T03:59:09.383833Z","iopub.status.idle":"2023-04-03T03:59:09.464901Z","shell.execute_reply.started":"2023-04-03T03:59:09.383791Z","shell.execute_reply":"2023-04-03T03:59:09.463558Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"+--------------------+---------------+-------+\n|            col_name|      data_type|comment|\n+--------------------+---------------+-------+\n|                  ID|         string|   null|\n|                Date|         string|   null|\n|            ID_Order|         double|   null|\n|     ID_Item_ordered|         double|   null|\n|          Units_sold|            int|   null|\n|                 SLA|            int|   null|\n|    Product_Category|         string|   null|\n|   Analytic_Category|         string|   null|\n|        Sub_category|         string|   null|\n|product_analytic_...|         string|   null|\n|                 MRP|            int|   null|\n|     Procurement_SLA|            int|   null|\n|                 GMV|         string|   null|\n|# Partition Infor...|               |       |\n|          # col_name|      data_type|comment|\n|                 GMV|         string|   null|\n|                    |               |       |\n|# Detailed Table ...|               |       |\n|            Database|       dmart_db|       |\n|               Table|sales_partition|       |\n+--------------------+---------------+-------+\nonly showing top 20 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Lets take another file\n\nfirst_sales = spark.read.csv(\"/kaggle/input/datasetbackups/dmart/firstfile.csv\",\n                            inferSchema=True,header=True,sep=',')","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:02:25.648845Z","iopub.execute_input":"2023-04-03T04:02:25.649266Z","iopub.status.idle":"2023-04-03T04:02:29.196721Z","shell.execute_reply.started":"2023-04-03T04:02:25.649226Z","shell.execute_reply":"2023-04-03T04:02:29.195825Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"first_sales.select(\"Date\",\"Sales_name\",\"gmv_new\",\"units\").show(2)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:04:27.977411Z","iopub.execute_input":"2023-04-03T04:04:27.977895Z","iopub.status.idle":"2023-04-03T04:04:28.132635Z","shell.execute_reply.started":"2023-04-03T04:04:27.977857Z","shell.execute_reply":"2023-04-03T04:04:28.131700Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"+-------------------+------------+-------+-----+\n|               Date|  Sales_name|gmv_new|units|\n+-------------------+------------+-------+-----+\n|2015-07-01 00:00:00|No Promotion| 3040.0|    1|\n|2015-07-01 00:00:00|No Promotion|  310.0|    1|\n+-------------------+------------+-------+-----+\nonly showing top 2 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Lets partition this dataframe on Sales_name and gmv_new. Lets count\nfirst_sales.count()","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:05:14.497567Z","iopub.execute_input":"2023-04-03T04:05:14.498456Z","iopub.status.idle":"2023-04-03T04:05:15.395356Z","shell.execute_reply.started":"2023-04-03T04:05:14.498406Z","shell.execute_reply":"2023-04-03T04:05:15.393877Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"1578079"},"metadata":{}}]},{"cell_type":"code","source":"#Before partitioning lets trimout the date, and select 4 columns\n\nfirst_sales.selectExpr(\"split_part(Date, ' ',1) as day_date\",\n                    \"Sales_name\", \"gmv_new\", \"units\").show(2)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:09:02.938597Z","iopub.execute_input":"2023-04-03T04:09:02.939087Z","iopub.status.idle":"2023-04-03T04:09:03.093475Z","shell.execute_reply.started":"2023-04-03T04:09:02.939048Z","shell.execute_reply":"2023-04-03T04:09:03.092031Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"+----------+------------+-------+-----+\n|  day_date|  Sales_name|gmv_new|units|\n+----------+------------+-------+-----+\n|2015-07-01|No Promotion| 3040.0|    1|\n|2015-07-01|No Promotion|  310.0|    1|\n+----------+------------+-------+-----+\nonly showing top 2 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"trimed_sales = first_sales.selectExpr(\"split_part(Date, ' ',1) as day_date\",\n                    \"Sales_name\", \"gmv_new\", \"units\")","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:09:19.936729Z","iopub.execute_input":"2023-04-03T04:09:19.937164Z","iopub.status.idle":"2023-04-03T04:09:19.953191Z","shell.execute_reply.started":"2023-04-03T04:09:19.937127Z","shell.execute_reply":"2023-04-03T04:09:19.952085Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"trimed_sales.write.saveAsTable(\"trimed_sales_partition\",\n                              mode='overwrite',\n                              format='parquet',\n                              partitionBy=['Sales_name','gmv_new'])","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:10:33.065718Z","iopub.execute_input":"2023-04-03T04:10:33.066180Z","iopub.status.idle":"2023-04-03T04:17:00.842315Z","shell.execute_reply.started":"2023-04-03T04:10:33.066134Z","shell.execute_reply":"2023-04-03T04:17:00.841308Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"!ls /kaggle/working/spark-warehouse/dmart_db.db/sales_partition/ | head -n 10","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:18:42.001885Z","iopub.execute_input":"2023-04-03T04:18:42.002353Z","iopub.status.idle":"2023-04-03T04:18:43.144473Z","shell.execute_reply.started":"2023-04-03T04:18:42.002310Z","shell.execute_reply":"2023-04-03T04:18:43.142883Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"GMV= \nGMV=0\nGMV=10\nGMV=100\nGMV=1000\nGMV=10000\nGMV=10002\nGMV=1001\nGMV=10010\nGMV=10017\nls: write error: Broken pipe\n","output_type":"stream"}]},{"cell_type":"code","source":"SQL(\"SHOW PARTITIONS trimed_sales_partition\").show(2,truncate=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:20:33.554896Z","iopub.execute_input":"2023-04-03T04:20:33.556188Z","iopub.status.idle":"2023-04-03T04:20:34.082856Z","shell.execute_reply.started":"2023-04-03T04:20:33.556122Z","shell.execute_reply":"2023-04-03T04:20:34.081977Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"+-----------------------------+\n|partition                    |\n+-----------------------------+\n|Sales_name=BED/gmv_new=1000.0|\n|Sales_name=BED/gmv_new=1003.0|\n+-----------------------------+\nonly showing top 2 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls /kaggle/working/spark-warehouse/dmart_db.db/trimed_sales_partition/","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:19:20.938946Z","iopub.execute_input":"2023-04-03T04:19:20.939419Z","iopub.status.idle":"2023-04-03T04:19:22.037724Z","shell.execute_reply.started":"2023-04-03T04:19:20.939376Z","shell.execute_reply":"2023-04-03T04:19:22.036260Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"'Sales_name=BED'\t\t\t'Sales_name=Independence Sale'\n'Sales_name=BSD-5'\t\t\t'Sales_name=No Promotion'\n'Sales_name=Big Diwali Sale'\t\t'Sales_name=Pacman'\n'Sales_name=Christmas & New Year Sale'\t'Sales_name=Rakshabandhan Sale'\n'Sales_name=Daussera sale'\t\t'Sales_name=Republic Day'\n'Sales_name=Eid & Rathayatra sale'\t'Sales_name=Valentine%27s Day'\n'Sales_name=FHSD'\t\t\t _SUCCESS\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls /kaggle/working/spark-warehouse/dmart_db.db/trimed_sales_partition/Sales_name\\=BED | head -n 5","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:21:08.220098Z","iopub.execute_input":"2023-04-03T04:21:08.220572Z","iopub.status.idle":"2023-04-03T04:21:09.319449Z","shell.execute_reply.started":"2023-04-03T04:21:08.220527Z","shell.execute_reply":"2023-04-03T04:21:09.317920Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"gmv_new=1000.0\ngmv_new=1003.0\ngmv_new=1004.0\ngmv_new=10049.0\ngmv_new=1010.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Introducing Bucket By\n\nWhat is the difference between Bucket By and Partition By\n\nBucket By creates just files. While partition By creates folders based on the partition, and then places the files inside it.Example follows","metadata":{}},{"cell_type":"code","source":"trimed_sales.write.bucketBy(10, 'Sales_name').saveAsTable(\"bucketed_sales\")","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:24:44.507414Z","iopub.execute_input":"2023-04-03T04:24:44.508695Z","iopub.status.idle":"2023-04-03T04:24:50.986110Z","shell.execute_reply.started":"2023-04-03T04:24:44.508638Z","shell.execute_reply":"2023-04-03T04:24:50.984272Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"!ls /kaggle/working/spark-warehouse/dmart_db.db/bucketed_sales/ ","metadata":{"execution":{"iopub.status.busy":"2023-04-03T04:25:24.190182Z","iopub.execute_input":"2023-04-03T04:25:24.191092Z","iopub.status.idle":"2023-04-03T04:25:25.294344Z","shell.execute_reply.started":"2023-04-03T04:25:24.191047Z","shell.execute_reply":"2023-04-03T04:25:25.293066Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"_SUCCESS\npart-00000-9bf476ea-c936-417c-90d8-4af308d855ed_00001.c000.snappy.parquet\npart-00000-9bf476ea-c936-417c-90d8-4af308d855ed_00002.c000.snappy.parquet\npart-00000-9bf476ea-c936-417c-90d8-4af308d855ed_00003.c000.snappy.parquet\npart-00000-9bf476ea-c936-417c-90d8-4af308d855ed_00006.c000.snappy.parquet\npart-00001-9bf476ea-c936-417c-90d8-4af308d855ed_00001.c000.snappy.parquet\npart-00001-9bf476ea-c936-417c-90d8-4af308d855ed_00003.c000.snappy.parquet\npart-00001-9bf476ea-c936-417c-90d8-4af308d855ed_00005.c000.snappy.parquet\npart-00001-9bf476ea-c936-417c-90d8-4af308d855ed_00009.c000.snappy.parquet\npart-00002-9bf476ea-c936-417c-90d8-4af308d855ed_00000.c000.snappy.parquet\npart-00002-9bf476ea-c936-417c-90d8-4af308d855ed_00001.c000.snappy.parquet\npart-00002-9bf476ea-c936-417c-90d8-4af308d855ed_00005.c000.snappy.parquet\npart-00002-9bf476ea-c936-417c-90d8-4af308d855ed_00007.c000.snappy.parquet\npart-00003-9bf476ea-c936-417c-90d8-4af308d855ed_00001.c000.snappy.parquet\npart-00003-9bf476ea-c936-417c-90d8-4af308d855ed_00007.c000.snappy.parquet\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Why these many table partitioned?\n\nTable partitioning is only the beginning. When we read these partition back, we can learn lot more. \n\nIn part-2 of this file we will see how to read the file and folders using Spark... Stay Tuned","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}